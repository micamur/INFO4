# RI 1 - Introduction

**Cours.** <https://hmul8r6b.imag.fr/doku.php/>

**Slide** : <https://hmul8r6b.imag.fr/lib/exe/fetch.php?media=accesinfoi-ii.pdf>

## Indexation et représentation

On s'intéresse au modèle **RI vectoriel** de 1965 (les modèles suivants utilisent les mêmes grands principes).

À partir des documents, l'étape principale consiste à créer le vocabulaire.

### Prétraitements linguistiques

#### Segmentation

**Segmentation.** Découper une chaîne de caractères en éléments syntaxiques ou mots (*tokenisation* en anglais).

**Occurences de mots.** Nombre de mots, plusieurs peuvent être identiques (dans un **vocabulaire** ils sont tous différents).

> *Remarque.* Difficultés avec chaque langue : par exemple en allemand il y a de très longs mots composés et en chinois il n'y a pas d'espaces.

> *Remarque.* En cours : NLTK Natural Language Toolkit. Fourni notamment des possibilités de segmentation.-

#### Normalisation

La **normalisation textuelle** rend les mots d’une même famille sous leur **forme canonique** (ponctuation, casse, accents, etc.).

**Algorithme de Porter.** Plusieurs règles avec une prémisse et une conclusion (par exemple avec `ies -> y` on a `daisies -> daisy`).

**Racinisation / Lemmatisation.** Troncature / Conjugaisons (par exemple)

**Anti-dictionnaire.** Mots inutiles à la recherche d'information (la, du, y, etc.).

**Corpus de documents.** Ensemble de documents dans la collection.

**Sac-de-mots** après racinisation + anti-dictionnaire de *l’information donne sens`a l’esprit* : *inform, don, sens, esprit*

### Deux lois de base en RI

La **loi de Heaps** et la **loi de Zipf**.

### Exercices

Prenons la collection Wikipédia vue plus haut.

1. Proabilité *expérimentale* d'apparition du mot ***de*** dans la collection ?

> $$fc_{\text{exp}}(...)$$ est la fréquence expérimentale d'un mot.

Soit $M = \text{# total d'occurences des mots} = 696 668 157$.

$$
P_{\text{exp}}(\text{"de"}) = {fc_{\text{exp}}(\text{"de"}) \over M} = {36 875 868 \over 696 668 157} = 0.053
$$

2. Estimation *théorique* du nombre d'apparition du mot ***de*** dans la collection ?

Soit $M_y = \text{# total de mots} = 757 476$.

$$
\lambda = {M \over ln(M_y)} = {696 668 157 \over ln(757 476)} = 51 461 158.95
$$

$$
fc_{\text{th}}(\text{"de"}) = {\lambda \over rang(\text{"de"})} = {51 461 158.95 \over 1} = 51 461 158.95
$$

On a une marge d'erreur de l'ordre de $0,7$.

3. Quel serait le nombre moyen d’apparitions du mot le plus fréquent, ***de***, dans un document de taille 416 mots ?

$$
P_{exp}(\text{ de }) * 416 = 0,053 * 416 = 22
$$



.
