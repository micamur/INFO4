# RI TD1 -- Stockage

> **Slide associé** : <https://hmul8r6b.imag.fr/lib/exe/fetch.php?media=accesinfoi-ii.pdf> (n°1)

## Exercice 1 -- Pondération

> **Slides utiles** : 14 (Quelques statistiques) et 23 (Pondération de termes)

- Document $d$ contenant "deux un deux"
- $N = 1000$ documents dans la collection
- $df_{\text{"deux"}} = 150$ : "deux" apparaît dans 150 documents
- $df_{\text{"un"}} = 50$ : "un" apparaît dans 50 documents
- Pondération : $ptf_{ti, d} = tft_{i, d}$
- $pdf_{ti, d}$ en log népérien
- Normalisation : $n_d = 1$

$$
\begin{array}{lcl}
w_{i, d} & = & p_{tf_{t_i, d}} \times p_{df_{t_i}} \times n_d\\
 & = & tf_{i,d} \times idf_i \times 1\\
 & = & tf_{i,d} \times {N \over df_{t_i}} \times 1\\
\end{array}
$$

On veut calculer le poids des deux termes de $d$.

$$
w_{\text{un}, d} = 1 \times \ln({1000 \over 50}) \times 1 = 3,00
$$

$$
w_{\text{deux}, d} = 2 \times \ln({1000 \over 150}) \times 1 = 3,80
$$

> **Interpétation.** $w_{\text{deux}, d}$ n'est pas deux fois supérieur à $w_{\text{un}, d}$ même si il est deux fois plus présent dans le document $d$ car le mot deux est présent dans beaucoup de documents. Il perd ainsi de l'importance car une recherche qui renvoie beaucoup de résultats est moins pertinente.

\newpage

## Exercice 2 -- Représentation vectorielle

- Vocabulaire $V0$ : football, corners, penalties, sport, penalty, coupe, sports, coupes, rugby, collectif, corner
- Vocabulaire $V1$ : football, corner, penalt, sport, coup, rugb, collectif
- Vocabulaire $V1$ (trié alphabétiquement) : collectif, corner, coup, football, penalt, rugb, sport

Représentations vectorielles avec pondération binaires :

- $N = 3$ documents dans la collection
- $df_i = x$ : $i$ apparaît dans $x$ documents
  - football : 2
  - corner : 2
  - penalt : 2
  - sport : 2
  - coup : 2
  - rugb : 1
  - collectif : 2
- Pondération : $ptf_{ti, d} = tft_{i, d}$
- $pdf_{ti, d} = idf_i = {N \over df_{t_i}}$
- Normalisation : $n_d = 1$

Représentation vectorielle des documents avec des pondérations binaires pour $V1$ (trié alphabétiquement) :

- $d_1 = (0, 1, 0, 1, 1, 0, 0)$
- $d_2 = (0, 0, 1, 1, 1, 0, 1)$
- $d_3 = (1, 1, 1, 0, 0, 1, 1)$

\newpage

## Exercice 3 -- Indexation vectorielle

1. Anti-dictionnaire
   - $d_1$ : professeur parle recherche information textuelle
   - $d_2$ : recherche information domaine recherche intéresse nombreux problèmes
   - $d_3$ : modèle vectoriel recherche information modèle simple comprendre
2. Calcul des $pft$ à base de $tf
  - $d_1$
    - 1 : professeur, parle, recherche, information, textuelle
  - $d_2$
    - 2 : recherche
    - 1 : information, domaine, intéresse, nombreux, problèmes
  - $d_3$
    - 2 : modèle
    - 1 : vectoriel, recherche, information, simple, comprendre
3. Calcul des $pdf$ à base d'$idf$ : $\ln({N \over df_{t_i}})$ (nombre de documents du corpus / nombre de documents dans lesquels le mot apparaît) :
  - comprendre : $\ln({3 \over 1}) = \ln 3$
  - domaine : $\ln({3 \over 1}) = \ln 3$
  - information : $\ln({3 \over 3}) = \ln 1 = 0$
  - intéresse : $\ln({3 \over 1}) = \ln 3$
  - modèle : $\ln({3 \over 1}) = \ln 3$
  - nombreux : $\ln({3 \over 1}) = \ln 3$
  - parle : $\ln({3 \over 1}) = \ln 3$
  - problèmes : $\ln({3 \over 1}) = \ln 3$
  - professeur : $\ln({3 \over 1}) = \ln 3$
  - recherche : $\ln({3 \over 3}) = \ln 1 = 0$
  - simple : $\ln({3 \over 1}) = \ln 3$
  - textuelle : $\ln({3 \over 1}) = \ln 3$
  - vectoriel : $\ln({3 \over 1}) = \ln 3$


.
