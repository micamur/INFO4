% Communication Langagière -- TP2
% Claire VELUT et Mica MURPHY
% Mercredi 29 janvier 2020

# Introduction à UNICODE

## Exercice 1

### Q1

Certains fichiers s'affichent comme des symboles étranges au lieu du texte parce qu'ils ont besoin d'un encodage en particulier, les caractères utilisés ne sont pas forcément compris dans d'autres encodages.

### Q2

Au début du fichier il peut y avoir une indication de l'encodage utilisé, par exemple pour les fichiers Unicode, il y a normalement une séquence d'octets appelée *Byte Order Mark* (ou BOM). Ils n'y arrivent pas tous, par exemple Chrome détecte directement l'encodage du fichier `testAR.win` alors que Firefox non.

### Q3

L'affichage du fichier `testFR.txt` reste correct même quand on l'affiche avec l'encodage `Turkish Windows-1254`, ce n'est pas le cas pour le fichier `testIS.txt`. En effet, les caractères français existent dans l'encodage turc `Turkish Windows-1254` mais les caractères Islandais non.

\newpage

## Exercice 2

### Q1

Le code hexadécimal `0A` représente `Line Feed` soit un saut de ligne `\n`. C'est pour ça qu'on l'a toujours à la fin du résultat des commandes de type : `echo é | xxd`.

### Q2

On a besoin de 7 octets pour représenter `déçà`, en effet pour chaque lettre "normale" (ici `d`) on a besoin d'un seul octet et pour les caractères accentués on a besoin de deux octets (ici `é`, `ç` et `à`). Sa représentation est donnée ci-dessous (obtenue avec `echo déçà | xxd`).

```text
64c3 a9c3 a7c3 a0
```

### Q3

La commande `echo 4772C3BCC39F65 | xxd -p -r` nous permet de déterminer les glyphes associés au code hexadécimal `47 72 C3 BC C3 9F 65` soit la chaîne `Grüße`.

Avec la commande `echo Grüße | xxd` (et caractère par caractère) on remarque que les glyphes `G`, `r` et `e` sont encodés sur 1 octet tandis que les glyphes `ü` et `ß`, plus particuliers à l'allemand, sont encodés sur 2 octets.

### Q4

Pour le fichier `testEN.txt` a comme encodage l'`us-ascii` d'après la commande `file -i testEN.txt`. Lorsqu'on ouvre ce fichier en UTF-8, on ne remarque aucune différence, on en déduit donc que UTF-8 et US-ASCII sont deux encodages compatibles pour ce fichier, en l'occurence, US-ASCII est inclus dans UTF-8.

## Exercice 3

### Q1

Avec les commandes `xxd testFR.txt.utf8` et `xxd testFR.txt.iso8859-1` nous remarquons que la représentation la plus efficace est la représentation dans l'encodage `ISO-8859-1`. En effet, dans cette représentation tous les caractères sont codés sur 1 octet (même les caractères accentués). Voir ci-dessous la comparaison des deux encodages.

               | é      | (espace) | (LF) | à      | (LF) | A    | (LF) | ç      | a    | (LF) | (LF)
---------------|--------|----------|------|--------|------|------|------|--------|------|------|-----
**UTF-8**      | `C3A9` | `20`     | `0A` | `C3A0` | `0A` | `41` | `0A` | `C3A7` | `61` | `0A` | `0A`
**ISO-8859-1** | `E9`   | `20`     | `0A` | `E0`   | `0A` | `41` | `0A` | `E7`   | `61` | `0A` | `0A`

### Q2

Le `é` est représenté par `c3a9` en UTF-8 et par `e9` en ISO-8859-1.

\newpage

## Exercice 4

### Q1

En ouvrant les fichiers avec Libre Office, les caractères accentués de `testFR.txt` ne s'affichent pas correctement. Tous les caractères de `testRU.txt`, `testAR.txt` et `testGK.txt` s'affichent normalement.
Libre Office ne connaît pas l'encodage de `testFR.txt` : ISO-8859-1.

## Exercice 5

### Q1

En ouvrant `testAR.win` avec Vi, les caractères ne s'affichent pas correctement.

### Q2

Vi a essayer de détécter automatiquement l'encodage du fichier mais il l'a détécté comme étant codé avec Latin-1 (on a tapé `:set fileencoding` dans Vi pour afficher l'encodage du buffer courant).

## Exercice 6

### Q1

Les deux premiers octets dans le fichier converti en UTF-16 correspondent au BOM (cf. exercice 1, Q2), ici on lit `FFFE`.

`iconv -f UTF-8 -t UTF-16 files/testFR.txt.utf8 -o files/testFR.txt.utf16`

            | (BOM)  | é      | (espace) | (LF)   | à      | (LF)   | A      | (LF)   | ç      | a      | (LF)   | (LF)
-----------|--------|--------|----------|--------|--------|--------|--------|--------|--------|--------|--------|-------
**UTF-8**  |        | `C3A9` | `20`     | `0A`   | `C3A0` | `0A`   | `41`   | `0A`   | `C3A7` | `61`   | `0A`   | `0A`
**UTF-16** | `FFFE` | `E900` | `2000`   | `0A00` | `E000` | `0A00` | `4100` | `0A00` | `E700` | `6100` | `0A00` | `0A00`

### Q2

Les codes points Unicode et leur représentation en UTF-16 sont équivalentes (par exemple pour `é` le code point est `U+00E9` et sa représentation en UTF-16 est `\u00E9`).

### Q3

Nous avons converti le fichier `testFR.txt.utf8` en `testFR.txt.utf16BE` avec `iconv -f UTF-8 -t UTF-16BE files/testFR.txt.utf8 -o files/testFR.txt.utf16BE`.
Quand nous le comparons avec le fichier encodé en UTF-16, nous remarquons que UTF-16BE code les octets en big endian tandis que UTF-16 les code en little endian.
Si on précise `UTF-16BE` ou `UTF-16LE`, on ne voit plus le BOM au début du fichier avec xxd.
